# TwitterSentimentAnalysis

The SemEval dataset consists of 11 datasets of tweets collected between years 2013 and 2016. This dataset is a bit noisy, and two of them aren’t properly formatted with tab separators, causing some tweets to stack on top of each other. We decided to ignore these files and use only nine txt datasets in our experiments. In addition, we performed a couple of steps in preprocessing to make it easier to explore the dataset, such as parsing the dataset with spacy, removing @mention, lemmatizing each token with Spacy method’.lemma,’ removing special characters, doing spell correction because sometimes users use repeating characters to exaggerate their argument, i.e (sooo bad) to imply that it was not just bad but it was already too bad, and so on. Furthermore, the dataset is unbalanced, which means that it is not evenly distributed among the three classes offered (neutral, positive, and negative). The disadvantage of training the model on an unbalanced dataset is that when applied to real-world data, the model will be biased in favor of the dominant class. This is a challenge for us when attempting to forecast the minority class. To address this issue, we used the oversampling and undersampling methods to balance the data and monitor performance (accuracy, recall, precision and f-1 score). The oversampling method, particularly when using SMOTE, demonstrated the highest accuracy. Furthermore, we are experimenting with different classifiers with SMOTE, and the results show that the Logistic Regression classifier outperforms the others.
